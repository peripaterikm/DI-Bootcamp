{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60bf2bca-ea67-492c-9be8-6f77faf508e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –î–û: 891\n",
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: 0\n",
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –ü–û–°–õ–ï: 891\n",
      "–£–¥–∞–ª–µ–Ω–æ —Å—Ç—Ä–æ–∫: 0\n"
     ]
    }
   ],
   "source": [
    "#Ex.1\n",
    "import pandas as pd\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# –°–º–æ—Ç—Ä–∏–º —Ä–∞–∑–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã –¥–æ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤\n",
    "print(\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –î–û:\", df.shape[0])\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∏–º, –µ—Å—Ç—å –ª–∏ –ø–æ–ª–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã —Å—Ç—Ä–æ–∫\n",
    "duplicates = df.duplicated()\n",
    "print(\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:\", duplicates.sum())\n",
    "\n",
    "# –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã\n",
    "df_cleaned = df.drop_duplicates()\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∏–º —Ä–∞–∑–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è\n",
    "print(\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –ü–û–°–õ–ï:\", df_cleaned.shape[0])\n",
    "\n",
    "print(f\"–£–¥–∞–ª–µ–Ω–æ —Å—Ç—Ä–æ–∫: {df.shape[0] - df_cleaned.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bba8ff0d-c598-4eaf-a76c-b2bf13a84a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "----------------------------------------\n",
      "üìâ –†–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è —Å—Ç—Ä–æ–∫ —Å –ø—É—Å—Ç—ã–º Age: (714, 12)\n",
      "\n",
      "‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         0\n",
      "dtype: int64\n",
      "\n",
      "üëÄ –ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ DataFrame:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "#Ex.2\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "print(\"üîç –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 3. –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ Age (—Å–æ–∑–¥–∞—ë–º –∫–æ–ø–∏—é)\n",
    "df_dropped_age = df.dropna(subset=['Age'])\n",
    "print(f\"üìâ –†–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è —Å—Ç—Ä–æ–∫ —Å –ø—É—Å—Ç—ã–º Age: {df_dropped_age.shape}\")\n",
    "\n",
    "# 4. –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ Age —Å—Ä–µ–¥–Ω–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º\n",
    "df_age_filled = df.copy()\n",
    "df_age_filled['Age'] = df_age_filled['Age'].fillna(df_age_filled['Age'].mean())\n",
    "\n",
    "# 5. –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ Embarked –∑–Ω–∞—á–µ–Ω–∏–µ–º \"Unknown\"\n",
    "df_age_filled['Embarked'] = df_age_filled['Embarked'].fillna('Unknown')\n",
    "\n",
    "# 6. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –∏—Å–ø–æ–ª—å–∑—É–µ–º SimpleImputer –¥–ª—è Age\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_age_filled['Age'] = imputer.fit_transform(df_age_filled[['Age']])\n",
    "\n",
    "# 7. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "print(\"\\n‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏:\")\n",
    "print(df_age_filled.isnull().sum())\n",
    "\n",
    "# 8. –í—ã–≤–æ–¥ –ø–µ—Ä–≤—ã—Ö —Å—Ç—Ä–æ–∫ –æ–±–Ω–æ–≤–ª—ë–Ω–Ω–æ–≥–æ DataFrame\n",
    "print(\"\\nüëÄ –ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ DataFrame:\")\n",
    "print(df_age_filled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c444167-9d39-44f0-abcb-51d21a7d9b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sex  Sex_encoded  FamilySize  Embarked_C  Embarked_Q  Embarked_S  \\\n",
      "0    male            1           2       False       False        True   \n",
      "1  female            0           2        True       False       False   \n",
      "2  female            0           1       False       False        True   \n",
      "3  female            0           2       False       False        True   \n",
      "4    male            1           1       False       False        True   \n",
      "\n",
      "   Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Rare  \n",
      "0         False       False      True      False       False  \n",
      "1         False       False     False       True       False  \n",
      "2         False        True     False      False       False  \n",
      "3         False       False     False       True       False  \n",
      "4         False       False      True      False       False  \n"
     ]
    }
   ],
   "source": [
    "#Ex.3\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# 2. –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞ \"FamilySize\"\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "\n",
    "# 3. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ \"Title\" –∏–∑ \"Name\"\n",
    "df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# –ú–æ–∂–Ω–æ –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ä–µ–¥–∫–∏–µ —Ç–∏—Ç—É–ª—ã:\n",
    "df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', \n",
    "                                   'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
    "df['Title'] = df['Title'].replace('Ms', 'Miss')\n",
    "df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "# 4. –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "\n",
    "# Label encoding for 'Sex'\n",
    "le_sex = LabelEncoder()\n",
    "df['Sex_encoded'] = le_sex.fit_transform(df['Sex'])\n",
    "\n",
    "# One-hot encoding for 'Embarked' and 'Title'\n",
    "df = pd.get_dummies(df, columns=['Embarked', 'Title'], prefix=['Embarked', 'Title'])\n",
    "\n",
    "# 5. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "scaler = MinMaxScaler()\n",
    "df[['Age', 'Fare']] = scaler.fit_transform(df[['Age', 'Fare']])\n",
    "\n",
    "# 6. –ü—Ä–æ–≤–µ—Ä–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "print(df[['Sex', 'Sex_encoded', 'FamilySize'] + [col for col in df.columns if col.startswith('Embarked_') or col.startswith('Title_')]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c3b88e5-b7be-41f5-8c51-bca4148a82b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ IQR: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–±—Ä–æ—Å–æ–≤ –≤ 'Fare': 116\n",
      "üéØ IQR: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–±—Ä–æ—Å–æ–≤ –≤ 'Age': 11\n",
      "\n",
      "‚úÖ –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤ –ø–æ Z-score: (694, 12)\n",
      "\n",
      "üëÄ –ü–æ—Å–ª–µ –∫—ç–ø–ø–∏–Ω–≥–∞:\n",
      "–ú–∞–∫—Å Fare: 65.6344\n",
      "–ú–∏–Ω Fare: 0.0\n",
      "–ú–∞–∫—Å Age: 64.8125\n",
      "–ú–∏–Ω Age: 0.42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# --- I. –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ —Å –ø–æ–º–æ—â—å—é IQR ---\n",
    "def detect_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "\n",
    "# –ù–∞–π–¥—ë–º –≤—ã–±—Ä–æ—Å—ã\n",
    "outliers_fare = detect_outliers_iqr(df, 'Fare')\n",
    "outliers_age = detect_outliers_iqr(df, 'Age')\n",
    "\n",
    "print(f\"üéØ IQR: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–±—Ä–æ—Å–æ–≤ –≤ 'Fare': {len(outliers_fare)}\")\n",
    "print(f\"üéØ IQR: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–±—Ä–æ—Å–æ–≤ –≤ 'Age': {len(outliers_age)}\")\n",
    "\n",
    "# --- II. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: Z-–æ—Ü–µ–Ω–∫–∞ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è) ---\n",
    "# –£–¥–∞–ª–∏–º —Å—Ç—Ä–æ–∫–∏ —Å NaN –≤ –Ω—É–∂–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–∞—Ö\n",
    "df_no_na = df.dropna(subset=['Fare', 'Age'])\n",
    "\n",
    "# –í—ã—á–∏—Å–ª–∏–º Z-–æ—Ü–µ–Ω–∫—É\n",
    "z_scores = np.abs(stats.zscore(df_no_na[['Fare', 'Age']]))\n",
    "mask = (z_scores < 3).all(axis=1)\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω–∏–º —Ñ–∏–ª—å—Ç—Ä\n",
    "df_z_filtered = df_no_na[mask]\n",
    "print(f\"\\n‚úÖ –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤ –ø–æ Z-score: {df_z_filtered.shape}\")\n",
    "\n",
    "# --- III. –ö—ç–ø–ø–∏–Ω–≥ (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤) ---\n",
    "def cap_outliers(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    data[column] = np.where(data[column] > upper_bound, upper_bound,\n",
    "                            np.where(data[column] < lower_bound, lower_bound, data[column]))\n",
    "    return data\n",
    "\n",
    "df_capped = df.copy()\n",
    "df_capped = cap_outliers(df_capped, 'Fare')\n",
    "df_capped = cap_outliers(df_capped, 'Age')\n",
    "\n",
    "print(\"\\nüëÄ –ü–æ—Å–ª–µ –∫—ç–ø–ø–∏–Ω–≥–∞:\")\n",
    "print(\"–ú–∞–∫—Å Fare:\", df_capped['Fare'].max())\n",
    "print(\"–ú–∏–Ω Fare:\", df_capped['Fare'].min())\n",
    "print(\"–ú–∞–∫—Å Age:\", df_capped['Age'].max())\n",
    "print(\"–ú–∏–Ω Age:\", df_capped['Age'].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70c001f3-d110-4366-865a-87141ee8615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age     Fare  SibSp  Parch   Age_std  Fare_std  SibSp_std  Parch_std  \\\n",
      "0  22.0   7.2500      1      0 -0.530377 -0.518978   0.524570  -0.505895   \n",
      "1  38.0  71.2833      1      0  0.571831  0.691897   0.524570  -0.505895   \n",
      "2  26.0   7.9250      0      0 -0.254825 -0.506214  -0.551703  -0.505895   \n",
      "3  35.0  53.1000      1      0  0.365167  0.348049   0.524570  -0.505895   \n",
      "4  35.0   8.0500      0      0  0.365167 -0.503850  -0.551703  -0.505895   \n",
      "\n",
      "   Age_norm  Fare_norm  SibSp_norm  Parch_norm  \n",
      "0  0.271174   0.014151         0.2         0.0  \n",
      "1  0.472229   0.139136         0.2         0.0  \n",
      "2  0.321438   0.015469         0.0         0.0  \n",
      "3  0.434531   0.103644         0.2         0.0  \n",
      "4  0.434531   0.015713         0.0         0.0  \n"
     ]
    }
   ],
   "source": [
    "#Ex.5\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# –û—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã –∏ —É–¥–∞–ª–∏–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏\n",
    "numeric_cols = ['Age', 'Fare', 'SibSp', 'Parch']\n",
    "df_numeric = df[numeric_cols].dropna()\n",
    "\n",
    "# --- I. –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è (Standardization) ---\n",
    "# –ü—Ä–∏–≤–æ–¥–∏—Ç –¥–∞–Ω–Ω—ã–µ –∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é —Å–æ —Å—Ä–µ–¥–Ω–∏–º = 0 –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ–º = 1\n",
    "scaler_std = StandardScaler()\n",
    "standardized_data = scaler_std.fit_transform(df_numeric)\n",
    "\n",
    "df_standardized = pd.DataFrame(standardized_data, columns=[col + '_std' for col in df_numeric.columns])\n",
    "\n",
    "# --- II. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (Min-Max Normalization) ---\n",
    "# –ü—Ä–∏–≤–æ–¥–∏—Ç –¥–∞–Ω–Ω—ã–µ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω [0, 1]\n",
    "scaler_norm = MinMaxScaler()\n",
    "normalized_data = scaler_norm.fit_transform(df_numeric)\n",
    "\n",
    "df_normalized = pd.DataFrame(normalized_data, columns=[col + '_norm' for col in df_numeric.columns])\n",
    "\n",
    "# --- III. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏ ---\n",
    "df_result = pd.concat([df_numeric.reset_index(drop=True), df_standardized, df_normalized], axis=1)\n",
    "\n",
    "# –ü–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫\n",
    "print(df_result.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3a9bd0d-b1a3-4a70-b2c8-b67d7808ef5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sex_male  Embarked_Q  Embarked_S  Pclass_encoded\n",
      "0      True       False        True               2\n",
      "1     False       False       False               0\n",
      "2     False       False        True               2\n",
      "3     False       False        True               0\n",
      "4      True       False        True               2\n"
     ]
    }
   ],
   "source": [
    "#Ex.6\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# --- I. –û–ø—Ä–µ–¥–µ–ª–∏–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ---\n",
    "categorical_cols = ['Sex', 'Embarked', 'Pclass']  # Pclass –º–æ–∂–Ω–æ —Ç—Ä–∞–∫—Ç–æ–≤–∞—Ç—å –∫–∞–∫ –ø–æ—Ä—è–¥–∫–æ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é\n",
    "\n",
    "# --- II. One-hot encoding –¥–ª—è –Ω–æ–º–∏–Ω–∞—Ç–∏–≤–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö ---\n",
    "# 'Sex' –∏ 'Embarked' ‚Äî —ç—Ç–æ –Ω–æ–º–∏–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "df_encoded = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "# --- III. Label encoding –¥–ª—è –ø–æ—Ä—è–¥–∫–æ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π ---\n",
    "# 'Pclass' ‚Äî –∏–º–µ–µ—Ç –ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—è–¥–æ–∫ (1 > 2 > 3)\n",
    "label_encoder = LabelEncoder()\n",
    "df_encoded['Pclass_encoded'] = label_encoder.fit_transform(df['Pclass'])\n",
    "\n",
    "# (–ù–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ) –£–¥–∞–ª–∏–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π 'Pclass' –µ—Å–ª–∏ –Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤–æ–π\n",
    "df_encoded.drop(columns=['Pclass'], inplace=True)\n",
    "\n",
    "# --- IV. –†–µ–∑—É–ª—å—Ç–∞—Ç ---\n",
    "print(df_encoded[['Sex_male', 'Embarked_Q', 'Embarked_S', 'Pclass_encoded']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a19ee6c-703c-45ea-8751-56bce706deeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age     AgeGroup  AgeGroup_Child  AgeGroup_Teen  AgeGroup_Young Adult  \\\n",
      "0  22.0  Young Adult           False          False                  True   \n",
      "1  38.0        Adult           False          False                 False   \n",
      "2  26.0  Young Adult           False          False                  True   \n",
      "3  35.0  Young Adult           False          False                  True   \n",
      "4  35.0  Young Adult           False          False                  True   \n",
      "\n",
      "   AgeGroup_Adult  AgeGroup_Senior  \n",
      "0           False            False  \n",
      "1            True            False  \n",
      "2           False            False  \n",
      "3           False            False  \n",
      "4           False            False  \n"
     ]
    }
   ],
   "source": [
    "#Ex.7\n",
    "import pandas as pd\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# --- I. –£–¥–∞–ª–∏–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º –≤–æ–∑—Ä–∞—Å—Ç–æ–º ---\n",
    "df = df.dropna(subset=['Age'])\n",
    "\n",
    "# --- II. –°–æ–∑–¥–∞–¥–∏–º –≤–æ–∑—Ä–∞—Å—Ç–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–±–∏–Ω–Ω–∏–Ω–≥) ---\n",
    "# –ù–∞–ø—Ä–∏–º–µ—Ä: 0‚Äì12: –¥–µ—Ç–∏, 13‚Äì19: –ø–æ–¥—Ä–æ—Å—Ç–∫–∏, 20‚Äì35: –º–æ–ª–æ–¥—ã–µ –≤–∑—Ä–æ—Å–ª—ã–µ, 36‚Äì60: –≤–∑—Ä–æ—Å–ª—ã–µ, 61+: –ø–æ–∂–∏–ª—ã–µ\n",
    "age_bins = [0, 12, 19, 35, 60, 100]\n",
    "age_labels = ['Child', 'Teen', 'Young Adult', 'Adult', 'Senior']\n",
    "\n",
    "df['AgeGroup'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels)\n",
    "\n",
    "# --- III. –ü—Ä–∏–º–µ–Ω–∏–º one-hot encoding –∫ –≤–æ–∑—Ä–∞—Å—Ç–Ω—ã–º –≥—Ä—É–ø–ø–∞–º ---\n",
    "df_age_dummies = pd.get_dummies(df['AgeGroup'], prefix='AgeGroup')\n",
    "\n",
    "# --- IV. –û–±—ä–µ–¥–∏–Ω–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º DataFrame ---\n",
    "df = pd.concat([df, df_age_dummies], axis=1)\n",
    "\n",
    "# --- V. –ü—Ä–æ—Å–º–æ—Ç—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ ---\n",
    "print(df[['Age', 'AgeGroup'] + list(df_age_dummies.columns)].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdff2e9-6923-42a1-b78b-5765795fcb48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
